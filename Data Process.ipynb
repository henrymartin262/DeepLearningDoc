{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217ffb30",
   "metadata": {},
   "source": [
    "## 2.1 数据操作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037614c",
   "metadata": {},
   "source": [
    "### 入门 \n",
    "使用 arange 创建一个行向量 x，这个行向量包含以0开始的前12个整数，它们默认创建为整数，也可指定创建类型为浮点数，张量中的每个值都称为张量的元素（element）。**基础操作如下所示：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7926a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T14:14:52.558234Z",
     "start_time": "2024-06-15T14:14:52.551621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch               \n",
    "x = torch.arange(12)\n",
    "# tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
    "\n",
    "x.shape\n",
    "# torch.Size([12])\n",
    "\n",
    "#改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数\n",
    "x.reshape(3, 4)\n",
    "#tensor([[ 0,  1,  2,  3],\n",
    "#        [ 4,  5,  6,  7],\n",
    "#        [ 8,  9, 10, 11]])\n",
    "\n",
    "\n",
    "torch.zeros((2, 3, 4)) # 创建一个指定形状的全0张量\n",
    "# tensor([[[0., 0., 0., 0.],\n",
    "#          [0., 0., 0., 0.],\n",
    "#          [0., 0., 0., 0.]],\n",
    "\n",
    "#         [[0., 0., 0., 0.],\n",
    "#          [0., 0., 0., 0.],\n",
    "#          [0., 0., 0., 0.]]])\n",
    "\n",
    "torch.ones((2, 3, 4)) # 创建一个指定形状的全1张量\n",
    "# tensor([[[1., 1., 1., 1.],\n",
    "#          [1., 1., 1., 1.],\n",
    "#          [1., 1., 1., 1.]],\n",
    "\n",
    "#         [[1., 1., 1., 1.],\n",
    "#          [1., 1., 1., 1.],\n",
    "#          [1., 1., 1., 1.]]])\n",
    "\n",
    "torch.randn(3, 4) # 创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样\n",
    "# tensor([[-0.0801,  0.5529, -0.1306, -0.3035],\n",
    "#         [-0.2284,  1.1712,  0.2000, -1.9476],\n",
    "#         [ 0.4408, -0.3938, -2.2961, -0.4860]])\n",
    "\n",
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # 为张量赋予确定值\n",
    "# tensor([[2, 1, 4, 3],\n",
    "#         [1, 2, 3, 4],\n",
    "#         [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946df20a",
   "metadata": {},
   "source": [
    "### 运算符\n",
    "对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "039c10af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T14:21:27.992546Z",
     "start_time": "2024-06-15T14:21:27.983023Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算\n",
    "# (tensor([ 3.,  4.,  6., 10.]),\n",
    "#  tensor([-1.,  0.,  2.,  6.]),\n",
    "#  tensor([ 2.,  4.,  8., 16.]),\n",
    "#  tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
    "#  tensor([ 1.,  4., 16., 64.]))\n",
    "\n",
    "torch.exp(x)\n",
    "# tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])\n",
    "\n",
    "\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "# 将两个张量按照不同维度进行连结\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1) \n",
    "# (tensor([[ 0.,  1.,  2.,  3.],\n",
    "#          [ 4.,  5.,  6.,  7.],\n",
    "#          [ 8.,  9., 10., 11.],\n",
    "#          [ 2.,  1.,  4.,  3.],\n",
    "#          [ 1.,  2.,  3.,  4.],\n",
    "#          [ 4.,  3.,  2.,  1.]]),\n",
    "#  tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
    "#          [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
    "#          [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6eeee8",
   "metadata": {},
   "source": [
    "### 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5269f80a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T14:23:19.773147Z",
     "start_time": "2024-06-15T14:23:19.766232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b\n",
    "# (tensor([[0],\n",
    "#          [1],\n",
    "#          [2]]),\n",
    "#  tensor([[0, 1]]))\n",
    "\n",
    "a+b\n",
    "# tensor([[0, 1],\n",
    "#         [1, 2],\n",
    "#         [2, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f591fa4",
   "metadata": {},
   "source": [
    "### 索引&切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f13c0506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T14:25:35.980225Z",
     "start_time": "2024-06-15T14:25:35.971968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "X[-1], X[1:3]\n",
    "\n",
    "# (tensor([ 8.,  9., 10., 11.]),\n",
    "#  tensor([[ 4.,  5.,  6.,  7.],\n",
    "#          [ 8.,  9., 10., 11.]]))\n",
    "\n",
    "X[1, 2] = 9 # 更换单个元素\n",
    "# tensor([[ 0.,  1.,  2.,  3.],\n",
    "#         [ 4.,  5.,  9.,  7.],\n",
    "#         [ 8.,  9., 10., 11.]])\n",
    "\n",
    "X[0:2, :] = 12 # 按行更新元素\n",
    "# tensor([[12., 12., 12., 12.],\n",
    "#         [12., 12., 12., 12.],\n",
    "#         [ 8.,  9., 10., 11.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60245bd3",
   "metadata": {},
   "source": [
    "### 转换其它对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4f55775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T14:26:49.695411Z",
     "start_time": "2024-06-15T14:26:49.686887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)\n",
    "# (numpy.ndarray, torch.Tensor)\n",
    "\n",
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)\n",
    "# (tensor([3.5000]), 3.5, 3.5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f18119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T05:04:58.539629Z",
     "start_time": "2024-06-16T05:04:58.521137Z"
    }
   },
   "source": [
    "## 数据集预处理\n",
    "### 读取数据集\n",
    "创建一个人工数据集，并存储在CSV（逗号分隔值）文件 ../data/house_tiny.csv中。 以其他格式存储的数据也可以通过类似的方式进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8e471b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:09:21.991651Z",
     "start_time": "2024-06-16T09:09:21.986370Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok = True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # 列名\n",
    "    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2817dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:13:53.671754Z",
     "start_time": "2024-06-16T09:13:53.663266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa569d",
   "metadata": {},
   "source": [
    "### 处理缺失值\n",
    "“NaN”项代表缺失值。 为了处理缺失的数据，典型的方法包括插值法和删除法， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d276174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:20:54.116425Z",
     "start_time": "2024-06-16T09:20:54.068875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "numeric_cols = inputs.select_dtypes(include=['number']).columns \n",
    "# 这里使用均值来替代缺失的数据\n",
    "inputs[numeric_cols] = inputs[numeric_cols].fillna(inputs[numeric_cols].mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae4753ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:22:33.459199Z",
     "start_time": "2024-06-16T09:22:33.447977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0        True      False\n",
      "1       2.0       False       True\n",
      "2       4.0       False       True\n",
      "3       3.0       False       True\n"
     ]
    }
   ],
   "source": [
    "# dummy_na=True: 指定是否将缺失值（NaN）作为一个单独的类别进行编码。如果设置为 True，那么缺失值会被转换为一个额外的哑变量列,哑变量是指用 0 和 1 表示的二进制变量\n",
    "inputs = pd.get_dummies(inputs, dummy_na = True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a6797",
   "metadata": {},
   "source": [
    "### 转换为张量格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36619394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:27:32.164442Z",
     "start_time": "2024-06-16T09:27:28.564481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(inputs.to_numpy(dtype=float))\n",
    "y = torch.tensor(outputs.to_numpy(dtype=float))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c70e5",
   "metadata": {},
   "source": [
    "### 练习\n",
    "删除缺失值最多的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e040b415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:35:43.536987Z",
     "start_time": "2024-06-16T09:35:43.523893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before delete\n",
      "     A    B  C\n",
      "0  1.0  NaN  1\n",
      "1  2.0  2.0  2\n",
      "2  NaN  NaN  3\n",
      "3  4.0  4.0  4\n",
      "after delete\n",
      "     A  C\n",
      "0  1.0  1\n",
      "1  2.0  2\n",
      "2  NaN  3\n",
      "3  4.0  4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [np.nan, 2, np.nan, 4],\n",
    "    'C': [1, 2, 3, 4]\n",
    "})\n",
    "print(\"before delete\")\n",
    "print(data)\n",
    "\n",
    "# 计算每一列缺失值数量\n",
    "missing_counts = data.isnull().sum()\n",
    "\n",
    "# 找到缺失值最多的列\n",
    "col_to_drop = missing_counts.idxmax()\n",
    "\n",
    "# 删除缺失值最多的列\n",
    "data = data.drop(columns=col_to_drop)\n",
    "print(\"after delete\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21344174",
   "metadata": {},
   "source": [
    "## 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad1537",
   "metadata": {},
   "source": [
    "两个矩阵的按元素乘法称为Hadamard积（Hadamard product）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb216b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:41:04.801507Z",
     "start_time": "2024-06-16T09:41:04.790845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[  0.,   1.,   4.,   9.],\n",
       "         [ 16.,  25.,  36.,  49.],\n",
       "         [ 64.,  81., 100., 121.],\n",
       "         [144., 169., 196., 225.],\n",
       "         [256., 289., 324., 361.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone()\n",
    "A, A*B # Hadamard积"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bcf0c",
   "metadata": {},
   "source": [
    "将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0f634b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:41:58.523334Z",
     "start_time": "2024-06-16T09:41:58.517231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9.],\n",
       "        [10., 11., 12., 13.],\n",
       "        [14., 15., 16., 17.],\n",
       "        [18., 19., 20., 21.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "A+a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c413b",
   "metadata": {},
   "source": [
    "### 张量降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58be607d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:43:21.944722Z",
     "start_time": "2024-06-16T09:43:21.934897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype = torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef9fd9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:45:37.268741Z",
     "start_time": "2024-06-16T09:45:37.225233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)   #按列相加\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7eb485d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:33.857761Z",
     "start_time": "2024-06-16T09:46:33.853199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)  #按行相加\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fcfb6",
   "metadata": {},
   "source": [
    "通过将总和除以元素总数来计算平均值。 在代码中，我们可以调用函数来计算任意形状张量的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f8dced2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:48:20.634041Z",
     "start_time": "2024-06-16T09:48:20.625376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.5000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ebc9ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:49:13.224771Z",
     "start_time": "2024-06-16T09:49:13.216405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0)/A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf117651",
   "metadata": {},
   "source": [
    "### 非降维求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65cea987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:50:05.306613Z",
     "start_time": "2024-06-16T09:50:05.299251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8041f",
   "metadata": {},
   "source": [
    "通过广播让 A 除以 sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61aa453e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:50:41.939618Z",
     "start_time": "2024-06-16T09:50:41.933716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A/sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c07092",
   "metadata": {},
   "source": [
    "求累加总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0920169f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:38.888846Z",
     "start_time": "2024-06-16T09:51:38.832610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77555d0a",
   "metadata": {},
   "source": [
    "### 点积\n",
    "两个向量相同位置元素乘积之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "503b3061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:53:41.046982Z",
     "start_time": "2024-06-16T09:53:41.040153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype = torch.float32)\n",
    "x,y,torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddf97a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:55:27.991433Z",
     "start_time": "2024-06-16T09:55:27.890262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵向量积\n",
    "A.shape, x.shape, torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caaa83fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:56:06.077441Z",
     "start_time": "2024-06-16T09:56:05.992655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵乘法积\n",
    "B = torch.ones(4, 3)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830d3ec",
   "metadata": {},
   "source": [
    "### 范数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af7ed6",
   "metadata": {},
   "source": [
    "L2 范数\n",
    "对于一个向量来说，它的 L2 范数就是它的各元素平方和的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5204fdb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:59:21.379651Z",
     "start_time": "2024-06-16T09:59:21.325064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59505bab",
   "metadata": {},
   "source": [
    "L1 范数对于一个向量来说是各向量元素的绝对值之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95ffc676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:00:20.706181Z",
     "start_time": "2024-06-16T10:00:20.664798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7b8dd",
   "metadata": {},
   "source": [
    "Frobenius范数（Frobenius norm）是矩阵元素平方和的平方根："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2968a56f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:00:46.968188Z",
     "start_time": "2024-06-16T10:00:46.960090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef85e040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T11:08:47.712427Z",
     "start_time": "2024-06-16T11:08:47.704882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([40., 45., 50., 55.]),\n",
       " tensor([[0.0000, 0.0222, 0.0400, 0.0545],\n",
       "         [0.1000, 0.1111, 0.1200, 0.1273],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.3000, 0.2889, 0.2800, 0.2727],\n",
       "         [0.4000, 0.3778, 0.3600, 0.3455]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,A.sum(axis=0),A/A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f76b6",
   "metadata": {},
   "source": [
    "## 自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2f17c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:32:36.659127Z",
     "start_time": "2024-06-16T12:32:36.654095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94147c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:33:38.699803Z",
     "start_time": "2024-06-16T12:33:38.696130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 下面代码需要一个地方来存储梯度，不会在每次对一个参数求导时都分配新的内存\n",
    "x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n",
    "print(x.grad)  # 默认值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2caec1e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:35:01.068320Z",
     "start_time": "2024-06-16T12:35:01.055508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x,x)\n",
    "y\n",
    "#x是一个长度为4的向量，计算x和x的点积，得到了我们赋值给y的标量输出。 \n",
    "#接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985771ed",
   "metadata": {},
   "source": [
    "**注意事项**：前面这里 y 实际上是一个标量，标量关于向量的梯度是向量，并且与x拥有相同形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6e11581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:37:12.417326Z",
     "start_time": "2024-06-16T12:37:12.399014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fe495a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:38:04.058920Z",
     "start_time": "2024-06-16T12:38:04.051190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76fbd13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:39:02.732377Z",
     "start_time": "2024-06-16T12:39:02.722792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf1534",
   "metadata": {},
   "source": [
    "### 非标量变量的反向传播\n",
    "当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b54af181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:42:08.634920Z",
     "start_time": "2024-06-16T12:42:08.591668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n",
    "# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ec26f",
   "metadata": {},
   "source": [
    "然而，这种情况会出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，通常会试图计算一批训练样本中每个组成部分的损失函数的导数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96426732",
   "metadata": {},
   "source": [
    "### 分离计算\n",
    "假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 如果想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用，这里就需要用**分离计算**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c3e2e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:47:31.553058Z",
     "start_time": "2024-06-16T12:47:31.494329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach() # u 与 y 有相同的值，但是 u 会被作为常数处理，不在看作是 x 的函数\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090bb79",
   "metadata": {},
   "source": [
    "### python 控制流梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf7e89d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:55:39.035125Z",
     "start_time": "2024-06-16T12:55:39.029515Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    print(b)\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "        print(c)\n",
    "    else:\n",
    "        c = 100 * b\n",
    "        print(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78d145",
   "metadata": {},
   "source": [
    "然后计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80af3032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:55:41.171640Z",
     "start_time": "2024-06-16T12:55:41.162222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1794.2429, grad_fn=<MulBackward0>)\n",
      "tensor(-179424.2969, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-0.2190, requires_grad=True),\n",
       " tensor(819200., grad_fn=<DivBackward0>),\n",
       " tensor(819200.))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "\n",
    "a, d/a, a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8bdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58cd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b5fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
